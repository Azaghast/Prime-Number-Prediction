{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n",
      "[ 2.  3.  5.  7. 11. 13. 17. 19. 23. 29. 31. 37. 41. 43. 47. 53. 59. 61.\n",
      " 67. 71.]\n"
     ]
    }
   ],
   "source": [
    "lines = open('C:\\\\Users\\\\Azaghast\\\\Downloads\\\\P-1000000\\\\P-1000000.txt','r').readlines()\n",
    "\n",
    "primes = []\n",
    "\n",
    "for line in range(len(lines)):\n",
    "    primes.append(lines[line].split(',')[1])\n",
    "\n",
    "primes = np.asarray((primes),dtype='float64')\n",
    "print(primes.shape)\n",
    "print(primes[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n",
      "[0.69314718 1.09861229 1.60943791 1.94591015 2.39789527 2.56494936\n",
      " 2.83321334 2.94443898 3.13549422 3.36729583 3.4339872  3.61091791\n",
      " 3.71357207 3.76120012 3.8501476  3.97029191 4.07753744 4.11087386\n",
      " 4.20469262 4.26267988]\n"
     ]
    }
   ],
   "source": [
    "primes_log = np.log(primes)\n",
    "print(primes_log.shape)\n",
    "print(primes_log[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999940, 60) (999940,) \n",
      "\n",
      "[0.69314718 1.09861229 1.60943791 1.94591015 2.39789527 2.56494936\n",
      " 2.83321334 2.94443898 3.13549422 3.36729583 3.4339872  3.61091791\n",
      " 3.71357207 3.76120012 3.8501476  3.97029191 4.07753744 4.11087386\n",
      " 4.20469262 4.26267988 4.29045944 4.36944785 4.41884061 4.48863637\n",
      " 4.57471098 4.61512052 4.63472899 4.67282883 4.69134788 4.72738782\n",
      " 4.84418709 4.87519732 4.91998093 4.93447393 5.00394631 5.01727984\n",
      " 5.05624581 5.0937502  5.11799381 5.15329159 5.18738581 5.19849703\n",
      " 5.25227343 5.26269019 5.28320373 5.29330482 5.35185813 5.40717177\n",
      " 5.42495002 5.433722   5.45103845 5.47646355 5.48479693 5.52545294\n",
      " 5.54907608 5.57215403 5.59471138 5.60211882 5.62401751 5.63835467] \n",
      "\n",
      "[16.55538579 16.55538618 16.55538734 16.55538773 16.55539161 16.55539277\n",
      " 16.55539393 16.55539471 16.55539664 16.55539806 16.55539858 16.55539897\n",
      " 16.5554     16.55540091 16.55540116 16.55540129 16.55540168 16.55540246\n",
      " 16.5554031  16.55540426 16.55540439 16.55540543 16.55540581 16.5554071\n",
      " 16.55540749 16.55540827 16.55540891 16.55541008 16.55541085 16.55541124\n",
      " 16.55541279 16.55541292 16.55541447 16.55541705 16.55541718 16.55541744\n",
      " 16.55541782 16.55541834 16.55541899 16.55541989 16.5554217  16.55542183\n",
      " 16.55542247 16.55542441 16.55542454 16.55542557 16.55542609 16.55542687\n",
      " 16.55542829 16.55542996 16.55543061 16.55543151 16.55543229 16.55543294\n",
      " 16.5554341  16.55543448 16.55543642 16.55543681 16.5554372  16.55543771] \n",
      "\n",
      "5.645446897643238\n",
      "16.555438101189427\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "batch_len = 60 #best so far\n",
    "\n",
    "for i in range(0,len(primes_log)-batch_len):\n",
    "    x.append(primes_log[i:i+batch_len])\n",
    "    y.append(primes_log[i+batch_len])\n",
    "\n",
    "x = np.asarray((x),dtype='float64')\n",
    "y = np.asarray((y),dtype='float64')\n",
    "\n",
    "\n",
    "print(x.shape, y.shape,'\\n')\n",
    "print(x[0],'\\n')\n",
    "print(x[-1],'\\n')\n",
    "print(y[0])\n",
    "print(y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "items = [i+1 for i in range(len(y))]\n",
    "\n",
    "plt.plot(items,y,color='black',label='ln(Next Prime)')\n",
    "plt.xlabel('Prime Index')\n",
    "plt.ylabel('ln(Prime)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(975097, 60) (975097,)\n",
      "(12343, 60) (12343,)\n",
      "(12500, 60) (12500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.0125,random_state=69420)\n",
    "train_x,val_x,train_y,val_y = train_test_split(train_x,train_y,test_size=0.0125,random_state=69420)\n",
    "\n",
    "print(train_x.shape,train_y.shape)\n",
    "print(val_x.shape,val_y.shape)\n",
    "print(test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.41086548 16.41086668 16.41086817 16.41086907 16.41086951 16.41087474\n",
      "  16.41087489 16.41087518 16.41087698 16.41087742 16.41087892 16.41088011\n",
      "  16.41088324 16.41088369 16.41088518 16.41088548 16.41088742 16.41088966\n",
      "  16.41088996 16.41089056 16.41089354 16.41089488 16.41089533 16.41089578\n",
      "  16.41089638 16.41089817 16.41089981 16.41090205 16.41090264 16.41090429\n",
      "  16.41090757 16.41090846 16.41090936 16.41090981 16.41091369 16.41091503\n",
      "  16.41091518 16.41091697 16.41091772 16.41091921 16.41092189 16.41092443\n",
      "  16.41092503 16.41092622 16.41092637 16.41092861 16.41093115 16.41093159\n",
      "  16.41093219 16.41093294 16.41093339 16.41093667 16.41093712 16.41093756\n",
      "  16.41093891 16.4109398  16.41094234 16.41094607 16.41094637 16.41094831]\n",
      " [15.53056589 15.53057453 15.53057561 15.53057669 15.53057813 15.53057993\n",
      "  15.53058209 15.53058569 15.53059001 15.53059289 15.53059828 15.53059936\n",
      "  15.53059972 15.53060728 15.53061016 15.53061052 15.5306134  15.53061592\n",
      "  15.530617   15.5306224  15.53062456 15.53062528 15.53062887 15.53063391\n",
      "  15.53063535 15.53063715 15.53064075 15.53064147 15.53064291 15.53064795\n",
      "  15.53064831 15.53065119 15.53065335 15.53065479 15.53065587 15.53065874\n",
      "  15.5306591  15.53066306 15.53066558 15.53066738 15.53066846 15.5306699\n",
      "  15.53067314 15.53067926 15.53068034 15.53068178 15.5306825  15.53068789\n",
      "  15.53068825 15.53069905 15.53070409 15.53070445 15.53070517 15.53070949\n",
      "  15.53071057 15.53071524 15.53071596 15.53071632 15.53072064 15.53072136]\n",
      " [16.09639519 16.09639764 16.09639785 16.09640091 16.09640316 16.09640439\n",
      "  16.09640704 16.09641052 16.09641195 16.09641297 16.0964142  16.09641502\n",
      "  16.09641563 16.09641604 16.09641665 16.09641849 16.09642217 16.09642237\n",
      "  16.09642462 16.09642667 16.09642891 16.09642953 16.09643096 16.09643157\n",
      "  16.0964328  16.09643341 16.09643464 16.09643811 16.09644056 16.09644363\n",
      "  16.09644424 16.09644506 16.09644567 16.09644669 16.09644792 16.09644812\n",
      "  16.0964518  16.09645344 16.09646223 16.09646754 16.09646774 16.09646938\n",
      "  16.09647245 16.09647326 16.09647388 16.09647674 16.09647878 16.09647939\n",
      "  16.09648001 16.09648185 16.09648246 16.09648287 16.09648491 16.09648675\n",
      "  16.09649023 16.09649084 16.09649166 16.0964939  16.09649595 16.09649636]\n",
      " [14.51175344 14.5117684  14.51177238 14.51178933 14.51179631 14.51180129\n",
      "  14.51180229 14.51181126 14.51182223 14.51182322 14.5118292  14.51183718\n",
      "  14.51184117 14.51184615 14.51184914 14.51186708 14.51187107 14.51187306\n",
      "  14.51187406 14.51187605 14.51188303 14.511894   14.51189699 14.51189798\n",
      "  14.51190396 14.51190596 14.51192689 14.51193885 14.51194184 14.5119538\n",
      "  14.51195779 14.51196377 14.51197772 14.51198071 14.51198171 14.51198769\n",
      "  14.51199068 14.51199666 14.51200563 14.51204151 14.5120435  14.51204749\n",
      "  14.51205845 14.51206742 14.51208635 14.51209732 14.51210031 14.5121013\n",
      "  14.5121033  14.51211326 14.51211625 14.5121312  14.51215213 14.51215711\n",
      "  14.51215811 14.51216608 14.51217305 14.51217804 14.51218501 14.51218999]\n",
      " [14.51036179 14.51037976 14.51038574 14.51039173 14.51039772 14.51040471\n",
      "  14.5104107  14.51043466 14.51045163 14.51045263 14.51045462 14.51046161\n",
      "  14.5104666  14.5104696  14.51047259 14.51047658 14.51047958 14.51048257\n",
      "  14.51048756 14.51049056 14.51049655 14.51051751 14.51052649 14.51053248\n",
      "  14.51053647 14.51053947 14.51055643 14.51055743 14.51056542 14.5105754\n",
      "  14.51058438 14.51058638 14.51058738 14.51059536 14.51061432 14.51061931\n",
      "  14.51063129 14.51063528 14.51064127 14.51065524 14.51065624 14.51065923\n",
      "  14.51066422 14.51067021 14.5106772  14.51068019 14.51069217 14.51069716\n",
      "  14.51070115 14.51070414 14.51071013 14.51072111 14.51072211 14.5107241\n",
      "  14.51076003 14.51076901 14.51078098 14.51078996 14.51079096 14.51080194]] \n",
      "\n",
      "[16.4109495  15.53072604 16.09650208 14.51219099 14.51081192]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[:5],'\\n')\n",
    "print(train_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#from sklearn.preprocessing import StandardScaler\\n#from sklearn.preprocessing import MinMaxScaler\\n#from sklearn.preprocessing import RobustScaler\\n#from sklearn.preprocessing import MaxAbsScaler\\n#from sklearn.preprocessing import Normalizer\\n\\nscaler = Normalizer()\\ntx_scaled = scaler.fit_transform(train_x)\\nvx_scaled = scaler.fit_transform(val_x)\\ntex_scaled = scaler.fit_transform(test_x)\\n\\nprint(np.min(tx_scaled),np.max(tx_scaled))\\nprint(np.min(vx_scaled),np.max(vx_scaled))\\nprint(np.min(tex_scaled),np.max(tex_scaled))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.preprocessing import RobustScaler\n",
    "#from sklearn.preprocessing import MaxAbsScaler\n",
    "#from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "tx_scaled = scaler.fit_transform(train_x)\n",
    "vx_scaled = scaler.fit_transform(val_x)\n",
    "tex_scaled = scaler.fit_transform(test_x)\n",
    "\n",
    "print(np.min(tx_scaled),np.max(tx_scaled))\n",
    "print(np.min(vx_scaled),np.max(vx_scaled))\n",
    "print(np.min(tex_scaled),np.max(tex_scaled))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def compute_train_val_test_loss(model,trnx,trny,valx,valy,tstx,tsty):\n",
    "    train_pred = model.predict(trnx)\n",
    "    train_mse, train_mae = mean_squared_error(train_pred,trny), mean_absolute_error(train_pred,trny)\n",
    "    val_pred = model.predict(valx)\n",
    "    val_mse, val_mae = mean_squared_error(val_pred,valy), mean_absolute_error(val_pred,valy)\n",
    "    test_pred = model.predict(tstx)\n",
    "    test_mse, test_mae = mean_squared_error(test_pred,tsty), mean_absolute_error(test_pred,tsty)\n",
    "    return [train_mse,train_mae,val_mse,val_mae,test_mse,test_mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    " \n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(train_x,train_y)\n",
    "\n",
    "#default parameters\n",
    "# train: mse = 4.854092873573726e-15 | mae = 2.0915432744933205e-08\n",
    "# val: mse = 2.8974676050941563e-08 | mae = 1.2070882228116168e-05\n",
    "# test: mse = 3.199805796746213e-08 | mae = 1.1323562149346781e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.109830825338855e-15, 2.207583099359244e-08, 6.909192252764876e-09, 9.403429366720007e-06, 2.8583197344051477e-08, 1.1734741356648044e-05]\n"
     ]
    }
   ],
   "source": [
    "tree_results = compute_train_val_test_loss(tree_reg,train_x,train_y,val_x,val_y,test_x,test_y)\n",
    "print(tree_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor #best one so far\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_jobs=-1)\n",
    "rf_reg.fit(train_x,train_y)\n",
    "\n",
    "#default parameters\n",
    "# train: mse = 1.9384429384367507e-09 | mae = 2.0303021494329557e-06\n",
    "# val: mse = 5.612622090512762e-09 | mae = 5.516235973658463e-06\n",
    "# test: mse = 5.98019525900258e-09 | mae = 5.161296261447476e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3317989748004871e-09, 1.9126039427963704e-06, 6.2328189407111e-09, 5.006569460996799e-06, 5.419747359276062e-09, 5.3655437303511635e-06]\n"
     ]
    }
   ],
   "source": [
    "rf_results = compute_train_val_test_loss(rf_reg,train_x,train_y,val_x,val_y,test_x,test_y)\n",
    "print(rf_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.2, max_depth=20, n_estimators=200)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt = GradientBoostingRegressor(max_depth=20,n_estimators=200,learning_rate=0.2)\n",
    "gbrt.fit(train_x,train_y)\n",
    "\n",
    "# max_depth=20,n_estimators=200,learning_rate=0.2\n",
    "# train: mse = 2.7886705771041244e-29 | mae = 4.983273430947665e-15\n",
    "# val: mse = 8.251987428800342e-08 | mae = 8.815952605326922e-06\n",
    "# test: mse = 8.815952605326922e-06 | mae = 8.486438306787672e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7886705771041244e-29, 4.983273430947665e-15, 8.251987428800342e-08, 8.815952605326922e-06, 7.540710234944235e-08, 8.486438306787672e-06]\n"
     ]
    }
   ],
   "source": [
    "gbrt_results = compute_train_val_test_loss(gbrt,train_x,train_y,val_x,val_y,test_x,test_y)\n",
    "print(gbrt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[479939. 479951. 479953. 479957. 479971. 480013. 480017. 480019. 480023.\n",
      " 480043. 480047. 480049. 480059. 480061. 480071. 480091. 480101. 480107.\n",
      " 480113. 480133.] \n",
      "\n",
      "13.08141429147497\n",
      "13.081439294339882\n",
      "13.081443461423257\n",
      "13.081451795537914\n",
      "13.081480964392247\n",
      "13.08156846585066\n",
      "13.081576798923585\n",
      "13.081580965434007\n",
      "13.081589298402774\n",
      "13.08163096220506\n",
      "13.081639294757217\n",
      "13.081643461007259\n",
      "13.081664291997106\n",
      "13.081668458143005\n",
      "13.081689288612148\n",
      "13.081730948248758\n",
      "13.081751777416258\n",
      "13.081764274708512\n",
      "13.081776771844584\n",
      "13.08181842783691\n",
      "\n",
      "\n",
      "13.081857789282328\n",
      "\n",
      " 480157.0 13.081868412737315\n"
     ]
    }
   ],
   "source": [
    "test_batch = np.asarray((primes[40000:40020]),dtype='float64')\n",
    "print(test_batch,'\\n')\n",
    "test_batch = np.log(test_batch)\n",
    "\n",
    "for i in test_batch:\n",
    "    print(i)\n",
    "\n",
    "print('\\n')\n",
    "test_batch = test_batch.reshape(1,20)\n",
    "test_batch_pred = rf_reg.predict(test_batch)\n",
    "\n",
    "for i in test_batch_pred:\n",
    "    print(i)\n",
    "\n",
    "print('\\n',primes[40021],np.log(primes[40021]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 60, 512)           1052672   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 60, 512)           2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 60, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,156,481\n",
      "Trainable params: 3,154,433\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tx = train_x.reshape((train_x.shape[0],train_x.shape[1],1))\n",
    "ty = train_y.reshape((train_y.shape[0],1))\n",
    "vx = val_x.reshape((val_x.shape[0],val_x.shape[1],1))\n",
    "vy = val_y.reshape((val_y.shape[0],1))\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((tx,ty))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(128)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((vx,vy))\n",
    "val_dataset = val_dataset.shuffle(buffer_size=1024).batch(128)\n",
    "\n",
    "lstm = keras.Sequential()\n",
    "lstm.add(keras.layers.LSTM(512,dropout=0.5,input_shape=(train_x.shape[1],1),return_sequences=True))\n",
    "lstm.add(keras.layers.BatchNormalization())\n",
    "lstm.add(keras.layers.LeakyReLU())\n",
    "lstm.add(keras.layers.LSTM(512,dropout=0.5))\n",
    "lstm.add(keras.layers.BatchNormalization())\n",
    "lstm.add(keras.layers.LeakyReLU())\n",
    "lstm.add(keras.layers.Dense(1))\n",
    "\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.compile(optimizer='adam',loss='mse',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 7618 steps\n",
      "Epoch 1/5\n",
      "7618/7618 [==============================] - 468s 61ms/step - loss: 1.0078 - mae: 0.3545\n",
      "Epoch 2/5\n",
      "1358/7618 [====>.........................] - ETA: 6:21 - loss: 0.0754 - mae: 0.2026"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-90699c733418>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\conda_tfgpu_testenv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm.fit(train_dataset,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_tfgpu_testenv] *",
   "language": "python",
   "name": "conda-env-conda_tfgpu_testenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
